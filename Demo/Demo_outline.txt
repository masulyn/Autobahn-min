30 minutes

Accompanying slides are here: https://docs.google.com/presentation/d/1uJP3fOR0OL3iRYlctZ4WdO_T6oSBP4DjV1C6eqvDVKc/edit?usp=sharing

Autobahn 2.0 Demo Outline:

Problem Statement:
	- Lazy evaluation can result in serious performance costs. Haskell allows users to force eager evaluation by inserting strictness annotations (or bangs), but manual bang placement is hard to reason about and time consuming. Autobahn 1.0 uses a genetic algorithm to automatically infer bang annotations that improve runtime performance, but often generates large numbers of superfluous bangs. Each bang potentially introduces non-termination or other semantic differences, so the user must inspect the safety of each bang. 
	- Example: infinite list, bangs in sum function
	- Problem: The large number of bangs generated by Autobahn 1.0 is time consuming for users to inspect.

Solution:
	- Autobahn 2.0 uses GHC profiling information to add a pre-search phase and a post-search phase before and after Autobahn 1.0’s genetic algorithm.
	- Pre-search phase: focuses search space
	- Post-search phase: individually test and remove bangs that have minimal impact

Results overview:
	- NoFib: reduced number of inferred bangs by 90.2% on average with 15.7% program performance degradation
	- Larger programs (garbage collection simulator): eliminated 81.8% of recommended bangs with 15.7% performance degradation.

—Start demo—


Background:
	- Lazy evaluation:
		- Expressions are only evaluated when their values are needed. Thunks store unevaluated expressions and its evaluation is delayed until another expression demands its value. While it reaps many benefits, it can cause serious performance problems when large amounts of memory are allocated to thunks.
		- GHC compiler uses backward static analysis to find locations for eager evaluation. It is necessarily conservative.
		- Bang patterns: manual strictness annotations. It is hard to find suitable locations for bang patterns
	- Autobahn 1.0:
		- Optimizer that helps programmers reduce their thunk usage by automatically inferring strictness annotations.
		- Input: unoptimized program, representative input, optional configuration file 
		- Runtime: multiple hours/over night
		- Genetic algorithm iteratively measures performances of a series of candidate bang placements.
		- Graph: Well performing candidates are preserved. Poorly performing candidates are discarded
		- Mutation: Randomly modifying a well performing candidate
		- Crossover: Combining half of two well performing candidates
		- Output: list of well performing candidates, which the user inspects
	- Optimization coverage: Autobahn 1.0 uses program source files as unit of granularity. By default optimizes all source code files. Coverage can be manually adjusted by adding or removing files.
	- Representative input: Input should allow reasonable running times and be representative of data the users intend to supply the finished program with.
	- GHC profiling and cost centres:
		- Profiling system adds annotations (cost centres) to the program and generates a report detailing the amount of time, memory, heap usage for each location.
		- Define hot spot/cold spot
		- Sample profile report

Autobahn 2.0
	- Hypothesis: Why too many bangs are generated
		- Dangerous bang: significantly degrade program performance or causes non-termination
		- Useless bang: neither improves nor degrades performance
		- Useful bang: improves program performance
		- Unfit chromosome: performs poorly as a whole but can mix dangerous, useless and useful bangs
		- Same with fit chromosomes
		- Autobahn 1.0 discards or performs entire chromosomes without separating the three types of useful bangs. So dangerous bangs still have chances of surviving and useful bangs may be removed.
	- Pre-search profiling:
		- Sets optimization coverage to be source files that contain at least one hot spot
		- Suggests library source files that may be optimized as well.
		- Benefits: limits search space, identifies potential external hot spots, identifies programs unsuitable for optimization
		- Example
	- Post-search bang elimination
		- Remove all turned off genes
		- Remove all turned on genes in cold spots
		- Individually test turned on genes in hot spots using absence impact threshold

Implementation
	- Program architecture
		- Optimization pipeline graph
	- Source locations
		- Modify Autobahn 1.0’s bit vector to associate each bit with the cost centre associated with the possible bang location. Map each bit to its corresponding source line.

Evaluation
	- Experimental setup:
		- All version of Autobahn compiled using GHC version 8.0.2
		- NoFib benchmarks compiled with GHC 8.0.2 using NoFib’s default flags, the flag -XBangPatterns, and the NoFib flag that enables profiling
		- Discarded benchmarks that failed to compile/run out of the box
		- Excluded benchmarks that Autobahn 1.0 fails to optimize because of very fast runtimes
		- 60 benchmarks remaining for running experiments
		- Runtime performance ratio: ratio of optimized program’s runtime to runtime of original program
		- Runtime performance ratio of 2: sentinel value indicating that the optimized version is non-terminating
		- Ran experiments 10 times to account for fluctuations
	- Pre-search 
		- Space reduction: 
			- Eliminated at least one file in 21 out of 60 benchmark programs
			- Remaining 39 benchmarks fall into two categories:
				- 33 benchmarks did not have any files eliminated by pre-search phase
				- 6 benchmarks were unsuitable for optimization
			- Interesting benchmarks: Autobahn 1.0 could not find winning chromosomes for anna, expert, symalg. After the pre-search phase, Autobahn was able to find meaningful bangs
	- Post-search bang reduction
		- On average 93.8% eliminated bangs with 33% worse runtime
		- Suggestion: lower the absenceImpact threshold to make the minimizer less aggressive
		- Interesting benchmarks: callback001 and pic have no cost centres that meet hotSpotThreshold
		- Suggestion: lower the hotSpotThreshold to capture “colder” locations
	- Combining pre-search and post-search
		- 5 benchmarks eliminated by Pre-search phase because of no hot spots
		- 3 benchmarks failed to optimize by either Autobahn 1.0 or Autobahn 2.0
		- only these 8 benchmarks consistently failed under Autobahn 2.0, while 12 consistently failed under Post-search phase => pre-search phase increases effectiveness of search
		- expert and calendar not only had bang reduction by 79.41% and 97.63%, but had performance improvements of 27.59% and 14.82%
		- atom had all bangs eliminated in post-search phase, but still had runtime performance ratio of 0.78 => atom’s original runtime fluctuates on its own
	-gcSimulator
		- garbage collection simulator that consumes program execution traces produced by the Elephant Tracks monitoring system
		- used first 1M of the batik trace file from the DaCapo benchmarks
		- lowered absenceImpact to 1%
		- evaluated optimized program on larger trace file sizes of 100M and 500M

—End demo—



Example: lcss (smaller program, never fails, clear example, no pre-search reduction)



