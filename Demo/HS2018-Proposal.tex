\newif \ifdraft \drafttrue
\documentclass[format=sigplan, review=true, 9pt]{acmart}
\renewcommand\footnotetextcopyrightpermission[1]{} % removes footnote
                                % with conference information in first column

\settopmatter{printacmref=false}

\usepackage{tikz}
\usetikzlibrary{shapes,arrows}
\usetikzlibrary{arrows.meta}

\definecolor{tuftsblue}{RGB}{72,145,206}
\newcommand{\SHOWCOMMENT}[1]{\ifdraft #1 \fi}
\newcommand{\ksf}[1]{\SHOWCOMMENT{{\color{tuftsblue} [K: #1]}}}

\newcommand{\cut}[1]{}
\newcommand{\acut}[1]{}

\newcommand{\appref}[1]{Appendix~\ref{#1}}
\newcommand{\secref}[1]{Section~\ref{#1}}
\newcommand{\tblref}[1]{Table~\ref{#1}}
\newcommand{\figref}[1]{Figure~\ref{#1}}
\newcommand{\listingref}[1]{Listing~\ref{#1}}

\newcommand{\eg}{\textit{e.g.}}

%\newcommand{\scaption}[1]{\caption{\small{#1}}}
\newcommand{\scaption}[1]{\caption{#1}}
%\setlength{\abovecaptionskip}{1ex}

\newcommand{\hotspot}[0]{hot spot}
\newcommand{\hotspots}[0]{hot spots}
\newcommand{\coldspot}[0]{cold spot}
\newcommand{\coldspots}[0]{cold spots}
\newcommand{\hotspotcost}[0]{\textit{hotSpotThreshold}}
\newcommand{\unfit}[0]{unfit}
\newcommand{\dangerous}[0]{dangerous}
\newcommand{\useful}[0]{useful}
\newcommand{\useless}[0]{useless}
\newcommand{\Ao}[0]{\textsc{Autobahn 1.0}}
\newcommand{\At}[0]{\textsc{Autobahn 2.0}}
\newcommand{\fit}[0]{fit}
\newcommand{\preopt}[0]{pre-search}
\newcommand{\postopt}[0]{post-search}
\newcommand{\Preopt}[0]{Pre-search}
\newcommand{\Postopt}[0]{Post-search}
\newcommand{\absim}[0]{\textit{absenceImpact}}
\newcommand{\overallThreshold}[0]{\textit{overallThreshold}}
\newcommand{\nonterm}[0]{non-terminating}
\newcommand{\unimp}[0]{unimproved}



\newcommand{\preoptElim}[0]{45}
\newcommand{\preoptFewerBangs}[0]{87.79\%}
\newcommand{\preoptPerformance}[0]{0.69}
\newcommand{\AoPerformance}[0]{0.75}
\newcommand{\postBangs}[0]{93.8\%}
\newcommand{\postRatioWorse}[0]{33\%}

\begin{document}
\acmJournal{PACMPL}
\title{\At:\break Minimizing Bangs while Maintaining Performance}
\acmConference[Haskell'18]{11th ACM SIGPLAN International Haskell Symposium}{September 27-28, 2018}{St.Louis, MO, United States}
\author{Marilyn Sun}
\affiliation{Tufts University}
\email{marilyn.sun@tufts.edu}
\author{Kathleen Fisher}
\affiliation{Tufts University}
\email{kfisher@cs.tufts.edu}
\acmYear{2018}

\begin{abstract}

While lazy evaluation has many advantages, it can result in serious
performance costs. To alleviate this problem, Haskell allows users to
force eager evaluation at certain program points by inserting
strictness annotations, known and written as bangs (!).
Unfortunately, manual bang placement
is labor intensive and difficult to reason about. The \Ao{}
optimizer uses a genetic algorithm to automatically infer bang annotations
that improve runtime performance. However, \Ao{} often generates
large numbers of superfluous bangs,
which is problematic because users must inspect each such bang to
determine whether it introduces non-termination or other semantic
differences. 
We introduce \At, which uses GHC
profiling information to reduce the number of superfluous bangs.
Specifically,
\At{} adds a \textit{\preopt{} phase} before \Ao's genetic algorithm
to focus the search space and a \textit{\postopt{} phase} to individually test
and remove bangs that have minimal impact. 
\cut{When evaluated on the NoFib
benchmark, the \preopt{} phase on average eliminated 45~locations for
potential bang placement per 100~LOC and reduced the number of bangs
eventually generated by 12.21\%. Overall, }
When evaluated on the NoFib benchmark suite, 
\At{} reduced the number of inferred bangs by 90.2\% on average,
\cut{\At{} reduces the number of
bangs generated from 11~bangs/100~LOC to 1 bang/100~LOC, }
while only degrading program performance by 15.7\% compared with the
performance produced by \Ao{}. 
In a case study on a garbage collection simulator, 
\At{} eliminated 81.8\% of the recommended bangs,  with the 
same 15.7\% optimization degradation when compared with \Ao{}.
\acut{
 Finally, it eliminated 91.3\% bangs with almost no runtime slowdown on
the \texttt{Aeson} parser library.}
\end{abstract}
\maketitle

\section{\Ao{} Produces Too Many Bangs}

\Ao~\cite{autobahn-wang} is a tool that helps Haskell programmers 
reduce their thunk usage by automatically inferring strictness
annotations. Users provide \Ao{} with an unoptimized
program, representative input, and an optional configuration file to
obtain an optimized version of the program over the course of a couple
of hours. If a program already contains strictness annotations, \Ao{} may remove existing annotations that do not improve program performance. 
\Ao{} uses a genetic algorithm to randomly search for
beneficial locations to place bangs in the program. The genetic
algorithm iteratively measures the runtime performances or memory consumptions of a series of
candidate bang placements, depending on the performance metric specified by the user. Candidates that improve upon the original
program's performance are preserved, and candidates that trigger
non-termination or worsen program performance are
eliminated. \Ao{} eventually returns a list
of well-performing candidates, ranked by how much each candidate
improves program performance. Because \Ao{} measures performance when the program is run on
the supplied input, the resulting annotations optimize the program
\textit{for that specific input}, which is why it is important for users
to provide representative input.  When run on different input, the
annotations could change the termination behavior of the program,
which may or may not be a problem.
Users then face the time-consuming task of inspecting candidate bang placements before applying them
to ensure the bangs maintain the desired semantics on all \textit{relevant}
inputs.  

\section{\At{}}

We present \At{}, an improved version of \Ao{} that aims
to reduce the number of generated bangs. 
\At{} introduces a \textit{\preopt{} phase} and
\textit{\postopt{} phase} that run before and after \Ao{},
respectively.  Both phases use information from GHC's profiler to
locate and eliminate ineffective bangs. 
GHC profiles allow users to better understand which locations
in a program consume the most resources.  The profiling system adds annotations
to the program and generates a report detailing the amount of runtime that is attributable to each location.
Any program source location where a bang may be added is
represented as a \textit{gene} that can be turned \textit{on},
corresponding to the presence of a bang, or \textit{off},
corresponding to its absence.  A \textit{chromosome} comprises all
of the genes within a file. We represent a chromosome as a
fixed-length bit vector, in which each bit indicates the presence or
absence of a bang at the corresponding location. Since a program is a
collection of source files, it is represented as a collection of bit
vectors, or chromosomes.
Intuitively, a bang that appears in a location that uses many resources, which we 
call a \textit{\hotspot}, is more likely to be \useful{}, while one in a
location using few resources, which we call a \textit{\coldspot}, is likely to
be \useless{}.  Leveraging that intuition, \At{} preserves bangs that appear
in \hotspots{} while eliminating those in \coldspots{}.

\subsection{The \Preopt{} Phase}
 \Ao{} uses program source files as the unit of granularity for 
the set of program locations to consider when inferring bangs. By
default, \Ao{} optimizes all source code files in the program's
directory. The \preopt{} phase uses profiling information to adjust the set of files that
\Ao{} considers during its optimization. Specifically, this phase instructs \Ao{} to
optimize files that contain locations that require significant
resources, skipping files that do not and
potentially adding files not originally included by the users.

Just as manually reasoning about bang placement can be difficult, 
so too reasoning about which files to optimize can be challenging.
The \preopt{} phase begins by generating a GHC time
and allocation profile for the unoptimized program by running it on 
user-provided representative input.
\At{} then sets the optimization coverage
for \Ao{} to be source files that contain at least one \hotspot{}. 
In addition, 
\At{} identifies library files that contain \hotspots{} and
suggests to users that they add local copies so the library source
files may be optimized as well. 
\Ao{} then optimizes the program as usual, except using a more
targeted set of files/chromosomes.
Note that this phase can both expand the search space, by identifying
library files that contain hotspots, as well as reduce it, by
identifying program source files with no \hotspots{}. 

\Preopt{} profiling offers three important benefits.
First, it can greatly reduce the number of bangs \Ao{} suggests by
limiting the search space to those program files that have a chance of
significantly impacting performance. 
Second, if a \hotspot{} is located in an external library file,
the \preopt{} phase can identify the relevant files so they can be
included in the optimization process. 
Third, it identifies programs that are potentially unsuitable for
\Ao{} optimization. If a program contains a large number of cost
centers that all contribute minimally to program runtime, there may
not be any way to substantially improve program performance by adding
bang annotations. If the \preopt{} phase concludes that
a program only contains \coldspots{}, it will alert the user and
abort, saving the time and effort of running the remaining phases, 
which are unlikely to identify significant performance improvements.

\subsection{The \Postopt{} Phase}
After \Ao{} runs, the \postopt{} phase individually tests
each candidate bang that falls within a costly location. Bangs that
do not significantly impact program performance are
eliminated.   The system is parameterized, so users can manage the
tradeoff between aggressively reducing the number of bangs and
preserving performance improvements.  In our experiments, we chose to
aggressively reduce the number bangs, accepting some performance
degradation over the level of optimization provided by \Ao{}.

After \Ao{} explores the search space and suggests a winning set of
chromosomes, \At{} uses GHC profiling information to eliminate any
bangs on those chromosomes that don't significantly contribute to
program performance. To that end, 
the \postopt{} phase decides that any gene that is off in the winning
chromosomes should not have a bang in the final recommendation.
It removes these genes from further consideration. 
The \postopt{} phase then maps each remaining gene, which must be
turned on, to its corresponding cost center.  It turns off all genes
that do not fall within \hotspots{}, deciding not to recommend bangs
for the corresponding locations on the theory that such bangs are
likely to be \useless{}.  It then removes these genes from further
consideration. 

The remaining genes are the interesting ones in that they both
contain a bang and fall within a \hotspot{}. These genes require
further testing because they may still be \useless{}, failing to
improve program performance even though they fall within a \hotspot{}.
\cut{If they are \useless{}, they should be discarded. }
There is usually a sufficiently small number of remaining genes that
are both turned on and within a \hotspot{} that it is possible to
measure their impact one by one. Specifically, 
the \postopt{} phase tests each such gene in turn, turning
it off while keeping all the remaining bangs on.  It 
then runs the resulting program and compares its performance to that
of the winning chromosomes as determined by \Ao{}.
If the absence of the bang slows down the program by the value of the \absim{}
threshold parameter, the \postopt{} phase deems the bang useful and
decides to keep it. 
Otherwise, the bang is deemed \useless{} and is
discarded. The \absim{} threshold is adjustable; we set it to
6\%. The \postopt{} phase repeats this process for every bang
that is both in the winning chromosomes and in a \hotspot{}. 
The minimization result is the combination of all the surviving
bangs.

\section{Evaluation}

To calculate the performance of a particular benchmark using a
particular optimization system (\eg{}, \At{} or a 
restricted version using only a subset \At's phases), we ran the system under test on the benchmark 10
times to account for random fluctuations.
To compute summary statistics across all the benchmarks, 
we calculate the \cut{\ksf{harmonic} mean} average of the runtime performance ratios
and the \cut{\ksf{arithmetic} mean} average of the total number of suggested bangs
across all 60 benchmark programs. 

In our evaluation results:
\begin{itemize}
  \item We show that \At{} applied to the NoFib benchmark suite reduced
    the number of generated bangs by 90.2\% on average, while
    increasing the runtime of the optimized program by 15.7\% over the
    runtime of the program optimized by \Ao{} alone. We refer to this
    performance change as a 15.7\% \textit{optimization degradation}.
\cut{(2.0 runtime - 1.0 runtime)/original}
  \item We demonstrate that the \preopt{} phase removed at least
    one file from consideration in 21 of the benchmarks in the NoFib
    suite, corresponding to 35\% of the programs we considered.
    For these programs, the \preopt{} phase eliminated
    45~potential bang locations per 100~LOC, resulting in a mean bang
    reduction of 87.79\% across the entire benchmark suite. 
  \item We use a microbenchmark to show that the \preopt{} phase's
    suggestions for additional files to consider can improve \Ao{}'s
    optimization results by 86.6\%.
  \item We evaluate the \postopt{} phase on the NoFib benchmarks,
    showing it can reduce the number of inferred bangs by
    93.8\% with a 33\% optimization degradation.
  \item We use \At{} in a case study to optimize the performance of 
    \texttt{gcSimulator}~\cite{Ricci13}, a garbage collector
    simulator. The system reduced the number of inferred bangs by
    81.8\% with a 15.7\% optimization degradation.
    \end{itemize}

\section{Demo{}}

In our demo, we describe in detail the theory behind our approach. 
Specifically, we explain the significance of incorporating GHC profiling
information with an otherwise random genetic search, and why it is able to
automatically reduce the number of bangs inferred by \Ao{} while maintaining roughly the same
level of optimization. This portion of the demo also describes how bangs are sorted
into categories, filtered, and eliminated in each of the \preopt{} and \postopt{} phases, and provides
an overview of \At{}'s optimization pipeline.  
 
Additionally, we discuss implementation specifics such as the program architecture and 
the representation of \hotspots{}, \coldspots{}, bangs and source locations in our optimizer.
We also take a closer look at the results obtained while evaluating the effectiveness of \At{}. 
Finally, we demonstrate a typical use case of \At{} by running it on an example program and 
walking through the minimization process and outcome.


\bibliographystyle{abbrvnat}
\bibliography{autobahn}

\end{document}
